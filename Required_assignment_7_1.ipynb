{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PreciousAkpokighe/Churn-Prediction-Platform-Capstone-Design/blob/main/Required_assignment_7_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8581564c",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-cf93e9709258c408",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "8581564c"
      },
      "source": [
        "# Required assignment 7.1: Applying predictive modelling techniques to real-world data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fac3cfc",
      "metadata": {
        "id": "3fac3cfc"
      },
      "source": [
        "The goal of this assignment is to predict whether someoneâ€™s salary is above or below $50,000 a year based on a publicly available data set of census data. The original dataset can be found on UCI Repository: https://archive.ics.uci.edu/ml/datasets/adult"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b9ee5ed1",
      "metadata": {
        "id": "b9ee5ed1"
      },
      "outputs": [],
      "source": [
        "#Import the packages\n",
        "import pandas as pd\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3479b9a",
      "metadata": {
        "id": "f3479b9a"
      },
      "source": [
        "### Read the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "92f590be",
      "metadata": {
        "id": "92f590be"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.valentinmihov.com/2015/04/17/adult-income-data-set/\n",
        "# taken and modified slightly from https://fairmlbook.org/code/adult.html\n",
        "\n",
        "features = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
        "        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n",
        "        \"Hours per week\", \"Country\", \"Target\"] #feaures of the dataset\n",
        "\n",
        "# This will download 3.8M\n",
        "df_train = pd.read_csv(\"train_url.csv\", names=features, sep=r'\\s*,\\s*', # Corrected path\n",
        "                             engine='python', na_values=\"?\") #read csv training\n",
        "# This will download 1.9M\n",
        "df_test = pd.read_csv(\"test_url.csv\", names=features, sep=r'\\s*,\\s*', # Corrected path\n",
        "                            engine='python', na_values=\"?\", skiprows=1) #read csv test\n",
        "\n",
        "num_train = len(df_train) #number of training instances"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be226753",
      "metadata": {
        "id": "be226753"
      },
      "source": [
        "Replace the labels of the training and test sets so that \"Target = 1\" means high income and \"Target = 0\" means low income. The target column should be an integer (binary) column eventually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "93ca285c",
      "metadata": {
        "id": "93ca285c",
        "outputId": "fa0a0188-f3c3-4e1e-e1de-f13a13f93963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in training set target ['<=50K' '>50K' None]\n",
            "Unique values in test set target ['<=50K.' '>50K.']\n"
          ]
        }
      ],
      "source": [
        "#first list the training values possible\n",
        "print(\"Unique values in training set target\", df_train.Target.unique())\n",
        "print(\"Unique values in test set target\", df_test.Target.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "713fde31",
      "metadata": {
        "id": "713fde31"
      },
      "outputs": [],
      "source": [
        "#now we can replace the labels\n",
        "df_train.Target = df_train.Target.replace('<=50K', 0).replace('>50K', 1)\n",
        "df_test.Target = df_test.Target.replace('<=50K.', 0).replace('>50K.', 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6750343f",
      "metadata": {
        "id": "6750343f",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-996065d3d8df01c4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Question 1:\n",
        "The columns names and data type of columns are inspected. The missing values in each column for training and test sets are listed. Find the number of missing values in training and testing dataset. Answer the following.\n",
        "\n",
        "The columns are first listed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9795e54",
      "metadata": {
        "id": "d9795e54",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-56fa71a48a2e419b",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q1.1: List how many missing values there are in each column for training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8f8b425",
      "metadata": {
        "id": "a8f8b425",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-50e65306a8b5fb39",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "- List how many missing values (cells) there are in each column for the training and test sets.\n",
        "    \n",
        "- Compute the total number of missing cells in the training dataset and assign it to `missing_train`.\n",
        "\n",
        "- Compute the number of rows in the training dataset that contain at least one NaN and assign it to `missing_train_NaN`.\n",
        "\n",
        "- Divide `missing_train` by `missing_train_NaN` and assign it to `result1`.\n",
        "\n",
        "- Repeat the same steps for the test dataset and assign the ratio to `result2`.\n",
        "\n",
        "HINT: For computing the `missing_train_NaN`ensure to compute the missing rows with atleast one `NaN`. This can be done by using `.any(axis=1)`.\n",
        "\n",
        "To find the sum use `np.sum()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b992455c",
      "metadata": {
        "id": "b992455c",
        "outputId": "6a1868da-d576-4911-9b90-2bfb6fd90ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18865 entries, 0 to 18864\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Age             18865 non-null  int64  \n",
            " 1   Workclass       17810 non-null  object \n",
            " 2   fnlwgt          18865 non-null  int64  \n",
            " 3   Education       18865 non-null  object \n",
            " 4   Education-Num   18865 non-null  int64  \n",
            " 5   Martial Status  18865 non-null  object \n",
            " 6   Occupation      17807 non-null  object \n",
            " 7   Relationship    18865 non-null  object \n",
            " 8   Race            18865 non-null  object \n",
            " 9   Sex             18864 non-null  object \n",
            " 10  Capital Gain    18864 non-null  float64\n",
            " 11  Capital Loss    18864 non-null  float64\n",
            " 12  Hours per week  18864 non-null  float64\n",
            " 13  Country         18530 non-null  object \n",
            " 14  Target          18864 non-null  object \n",
            "dtypes: float64(3), int64(3), object(9)\n",
            "memory usage: 2.2+ MB\n"
          ]
        }
      ],
      "source": [
        "#first list the columns\n",
        "pd.set_option('max_colwidth', None)\n",
        "df_train.info(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "af73fab3",
      "metadata": {
        "id": "af73fab3",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9571c2cd2bf8c007",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "outputId": "5cccd55d-c377-4019-ee54-ceef6bfbda5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratio for training data set   1.7814088598402325\n",
            "Ratio for testing data set  1.8042588042588044\n"
          ]
        }
      ],
      "source": [
        "###GRADED CELL\n",
        "missing_train = None\n",
        "missing_train_NaN = None\n",
        "result1 = None\n",
        "missing_test = None\n",
        "missing_test_NaN = None\n",
        "result2 = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "missing_train = np.sum(df_train.isna().sum())\n",
        "missing_train_NaN = np.sum(df_train.isna().any(axis=1))\n",
        "result1 = missing_train/missing_train_NaN\n",
        "missing_test = np.sum(df_test.isna().sum())\n",
        "missing_test_NaN = np.sum(df_test.isna().any(axis=1))\n",
        "result2 = missing_test/missing_test_NaN\n",
        "###END SOLUTION\n",
        "\n",
        "print(\"Ratio for training data set  \" , result1)\n",
        "print(\"Ratio for testing data set \", result2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06fa725a",
      "metadata": {
        "id": "06fa725a",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d45c8e39188f6e51",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Question 2:\n",
        "The target variable is further investigated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63c498f",
      "metadata": {
        "id": "d63c498f",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eae430afacefa607",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q2.1: What fraction of Target is in the training and testing databases.\n",
        "\n",
        "Assign the values to `training_target` and `testing_target` respectivily.\n",
        "\n",
        "HINT: Use `.value_counts(normalize = True)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f7ef07c5",
      "metadata": {
        "id": "f7ef07c5",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-81409a91c7a8238a",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "outputId": "5a513d9e-5e49-4512-f6b5-aefd2deab2d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target counts in the training set is given by  Target\n",
            "0    0.76145\n",
            "1    0.23855\n",
            "Name: proportion, dtype: float64\n",
            "The target counts in the testing set is given by Target\n",
            "0    0.763774\n",
            "1    0.236226\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "### GRADED CELL\n",
        "training_target = None\n",
        "testing_target = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "training_target = df_train[\"Target\"].value_counts(normalize = True)\n",
        "testing_target = df_test[\"Target\"].value_counts(normalize = True)\n",
        "###END SOLUTION\n",
        "\n",
        "print(\"The target counts in the training set is given by \",training_target)\n",
        "print(\"The target counts in the testing set is given by\", testing_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faa60d87",
      "metadata": {
        "id": "faa60d87"
      },
      "source": [
        "If we classify everyone as a low-income instance, the accuracy, sensitivity, and specificity in the test set can be evaluated by considering the high-income class as the positive class, since our goal is to identify individuals who make more money."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fd5df3e3",
      "metadata": {
        "id": "fd5df3e3"
      },
      "outputs": [],
      "source": [
        "accuracy = len(df_test[df_test['Target']==0])/len(df_test)\n",
        "\n",
        "sensitivity = 0 #we never said \"1\" so we cannot classify any \"1\" correctly\n",
        "specificity = 1 #we say \"0\" to all instances, so we cannot miss any 0's"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0833e9ba",
      "metadata": {
        "id": "0833e9ba",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-36c9abf2ef4c8243",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q2.2: List the fraction of high income instances within each group of \"workclass\" separately in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bbffb56",
      "metadata": {
        "id": "6bbffb56",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e6bdf01ddaaf6dc1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Assign the output to `workclass`.\n",
        "\n",
        "HINT: Use .`groupby()`. Compute the `.mean()` of `['Target']` and sort it in ascending order using `.sort_values()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5522a6ac",
      "metadata": {
        "id": "5522a6ac",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-709b82b795980596",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "outputId": "f8a7003d-c13a-40d4-ca12-03ec6a899117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Workclass    Target\n",
            "2      Never-worked       0.0\n",
            "7       Without-pay       0.0\n",
            "3           Private  0.216587\n",
            "6         State-gov  0.270199\n",
            "5  Self-emp-not-inc  0.283992\n",
            "1         Local-gov  0.290939\n",
            "0       Federal-gov  0.370826\n",
            "4      Self-emp-inc  0.550769\n"
          ]
        }
      ],
      "source": [
        "###GRADED CELL\n",
        "#First group by workclasses, take target, average it, and then print it in an ascending way.\n",
        "workclass = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "workclass=df_train.groupby('Workclass', as_index=False)['Target'].mean().sort_values(by=['Target'], ascending=True)\n",
        "###END SOLUTION\n",
        "\n",
        "print(workclass)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a58884",
      "metadata": {
        "id": "41a58884",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f1c31bcd58d52562",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q2.3: Building on the previous question, apply the following simple classification rule to the test set: classify an instance as \"1\" (high income) if its workclass belongs to one of the two highest-earning groups.\n",
        "\n",
        "Using the confusion matrix, calculate and report the accuracy and sensitivity of this model.\n",
        "\n",
        "Compute accuracy and assign it `accuracy`. Accuracy can also be computed as a fraction of correct to total values.\n",
        "Compute sensitivity and assign it `sensitivity`.\n",
        "\n",
        "HINT: Sensitivity = $$ \\frac{TP}{TP + FN} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "15b46e50",
      "metadata": {
        "id": "15b46e50"
      },
      "outputs": [],
      "source": [
        "greedy_workclass = df_test.apply(lambda row: 1 if (row[\"Workclass\"] == \"Self-emp-inc\") or\\\n",
        "                                 (row[\"Workclass\"] == \"Federal-gov\") else 0, axis = 1) #apply the function to predict\n",
        "y_true = df_test.Target.astype(int).values\n",
        "y_pred = greedy_workclass.astype(int).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a648db51",
      "metadata": {
        "id": "a648db51"
      },
      "outputs": [],
      "source": [
        "#import sklearn's confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "156efe95",
      "metadata": {
        "id": "156efe95",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3c27e2f714da7829",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52fe00d2-9be6-492b-9cad-c5b006ff4c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is given by  0.7613782937166022\n",
            "The sensitivity is given by  0.1315652626105044\n"
          ]
        }
      ],
      "source": [
        "###GRADED CELL\n",
        "total = len(y_true)\n",
        "correct = cm[0][0] + cm[1][1]\n",
        "accuracy = None\n",
        "sensitivity = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "accuracy = correct/total\n",
        "sensitivity = cm[1][1] / (cm[1][0] + cm[1][1])\n",
        "###END SOLUTION\n",
        "\n",
        "print(\"The accuracy is given by \", accuracy)\n",
        "print(\"The sensitivity is given by \", sensitivity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8e59005",
      "metadata": {
        "id": "d8e59005",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-18b90c0bcdd67ace",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Question 3: Performing further statistics and outlier detection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f15f4e3",
      "metadata": {
        "id": "3f15f4e3",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-996cb4a916ac4eff",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q3.1: List the fraction of male and females within US citizens in the training set.\n",
        "\n",
        "Assign to answer to `US_Gender`.\n",
        "\n",
        "HINT: Use country = \"United-States\" and compute the `.value_counts(normalize = True)` on \"Sex\" attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8be53286",
      "metadata": {
        "id": "8be53286",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b6ddb091bbb04a19",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "outputId": "a5df9987-e462-4221-a7f2-1ae487b7ea4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gender distribution is given by  Sex\n",
            "Male      0.670556\n",
            "Female    0.329444\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "###GRADED CELL\n",
        "\n",
        "US_Gender = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "US_Gender = df_train[df_train[\"Country\"]==\"United-States\"][\"Sex\"].value_counts(normalize = True)\n",
        "###END SOLUTION\n",
        "\n",
        "print(\"The gender distribution is given by \",US_Gender)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4967a70c",
      "metadata": {
        "id": "4967a70c",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-392569edbdb667d0",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q3.2: What is the most common occupation (training set)?\n",
        "\n",
        "Assign the answer to `occupation`. Use `.idxmax()` to get the most common occupation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0a9105d3",
      "metadata": {
        "id": "0a9105d3",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-db33ac7ab98d24e3",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "outputId": "d251e7b5-908f-4108-b504-73f3109d587b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prof-specialty\n"
          ]
        }
      ],
      "source": [
        "###GRADED CELL\n",
        "occupation = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "occupation = df_train['Occupation'].value_counts().idxmax()\n",
        "###END SOLUTION\n",
        "\n",
        "print(occupation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b6a943b",
      "metadata": {
        "id": "5b6a943b",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4369401807719f92",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q3.3: Which occupations are the most common male and female instances, respectively (training set)?\n",
        "\n",
        "Assign your answers to `occupation_male` and `occupation_female`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "364b7573",
      "metadata": {
        "id": "364b7573",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-7633a8b615e2ef70",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "outputId": "c40510bb-98c5-4c3a-abe0-4408b64f6d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most common male occupation is  Craft-repair\n",
            "The most common female occupation is Adm-clerical\n"
          ]
        }
      ],
      "source": [
        "###GRADED CELL\n",
        "occupation_male = None\n",
        "occupation_female = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "occupation_male = df_train[df_train[\"Sex\"]==\"Male\"]['Occupation'].value_counts().idxmax()\n",
        "occupation_female = df_train[df_train[\"Sex\"]==\"Female\"]['Occupation'].value_counts().idxmax()\n",
        "###END SOLUTION\n",
        "\n",
        "print(\"The most common male occupation is \", occupation_male)\n",
        "print(\"The most common female occupation is\", occupation_female)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50325525",
      "metadata": {
        "id": "50325525",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-3f0b4d7b0a74fe02",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Plotting the histogram of the \"Age\" column using the training set data, setting it to 10 bins and reflecting the percentage of instances on the Y-axis, allows for visually assessing potential outliers, indicating whether they are more prevalent at the higher or lower end of the age range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a582cd82",
      "metadata": {
        "id": "a582cd82",
        "outputId": "d0ba66d0-9905-4e52-c3e3-fda84c81dae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df_train[\"Age\"].hist(bins=10, weights=np.ones_like(df_train[\"Age\"]) * 100. / len(df_train)).plot()\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d34a7b3d",
      "metadata": {
        "id": "d34a7b3d"
      },
      "source": [
        "The age on the $99$-th quantile is 74. So it is not an 'erronous' outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f496b8a9",
      "metadata": {
        "id": "f496b8a9",
        "outputId": "2782e8b0-9243-4f73-e6db-404073fc2778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(74.0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df_train[\"Age\"].quantile(0.99) #the \".quantile\" function of pandas datframe will be enough"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "525f9efa",
      "metadata": {
        "id": "525f9efa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-21340002bd3fa90b",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "The correlation analysis in the training set shows that among the numerical predictors, \"Education-Num\" and \"Age\" have the strongest positive correlations with the target variable. The correlation of \"Age\" with the target indicates a moderate positive relationship, suggesting that as age increases, the likelihood of belonging to the positive class (high income) tends to increase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "50ea4448-c469-467f-87b3-cebb9cab18e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ea4448-c469-467f-87b3-cebb9cab18e6",
        "outputId": "327eba40-6b1e-4c01-9e3a-887ee03b4890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Age', 'Workclass', 'fnlwgt', 'Education', 'Education-Num',\n",
            "       'Martial Status', 'Occupation', 'Relationship', 'Race', 'Sex',\n",
            "       'Capital Gain', 'Capital Loss', 'Hours per week', 'Country', 'Target'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_train.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "744a77e4-1176-4e35-bdaa-22281635f14f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "744a77e4-1176-4e35-bdaa-22281635f14f",
        "outputId": "ce684b77-b495-4539-88bd-84ccc4d6e512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age               0.228518\n",
            "fnlwgt           -0.010656\n",
            "Education-Num     0.329325\n",
            "Capital Gain      0.220598\n",
            "Capital Loss      0.152569\n",
            "Hours per week    0.224402\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "df_train.columns = df_train.columns.str.strip()\n",
        "\n",
        "if \"Target\" in df_train.columns:\n",
        "    target = df_train[\"Target\"]\n",
        "    df_train_num = df_train.select_dtypes(include=['number'])\n",
        "    correlations = df_train_num.corrwith(target, method='pearson')\n",
        "    print(correlations)\n",
        "else:\n",
        "    print(\"The 'Target' column does not exist in df_train.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9851c851",
      "metadata": {
        "id": "9851c851"
      },
      "outputs": [],
      "source": [
        "target = df_train[\"Target\"]\n",
        "df_train_num = df_train.select_dtypes(include=['number'])\n",
        "correlations = df_train_num.corrwith(target, method='pearson')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc389d7f",
      "metadata": {
        "id": "dc389d7f",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-54f4787199c4f191",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Question 4:Applying Linear Regression model for Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21413c37",
      "metadata": {
        "id": "21413c37",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ffd6aa4d55368bb4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "\n",
        "Linear Regression, as the name suggests, is a regression method but we would like to apply classification. For that the `NaN` values are first removed. A copy of `df_train()` is made and `.dropna()` is used to drop `NaN` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "30fe1d70",
      "metadata": {
        "id": "30fe1d70"
      },
      "outputs": [],
      "source": [
        "df_save = df_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7e309691",
      "metadata": {
        "id": "7e309691"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.dropna(how='any')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26ba37e",
      "metadata": {
        "id": "a26ba37e",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-937117e8bd6cc72b",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q4.1: Train a linear regression model on the training set.\n",
        "\n",
        "This has two steps. In Step 1, the numeric columns are picked and stored in an array `numericals`. In the Step 2, `LinearRegression()`is fit using `.fit(X,y)`.(3 marks)\n",
        "\n",
        "HINT: The input `X` and the output `y` are picked from `df_train` numerical inputs and Target.\n",
        "The model is assigned to `clf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "64e74edc",
      "metadata": {
        "id": "64e74edc"
      },
      "outputs": [],
      "source": [
        "#Step 1 -- take the numeric columns\n",
        "numericals = [] #start with an empty array\n",
        "for i in range(len(df_train.dtypes)): #for all columns\n",
        "    coltype = df_train.dtypes.iloc[i] #take the type of column\n",
        "    if coltype != 'object' and df_train.columns[i] != 'Target': #object types are the categorical variables\n",
        "        numericals.append(df_train.columns[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d71d8215",
      "metadata": {
        "id": "d71d8215",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6b33bde0037e4009",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "###GRADED CELL\n",
        "#Step 2 -- fit\n",
        "from sklearn.linear_model import LinearRegression\n",
        "X = None\n",
        "y = None\n",
        "clf = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "X = df_train[numericals] #training predictors\n",
        "y = df_train.Target #training target\n",
        "clf = LinearRegression().fit(X, y) #time to fit\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abea849",
      "metadata": {
        "id": "6abea849",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f8fea38b69f0f90a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q4.2: Apply the linear model that we just fit and predict the training target. Show the first 5 predictions\n",
        "\n",
        "Use `.predict(X)` and assign the result to `scores_linear_training`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "13ad1295",
      "metadata": {
        "id": "13ad1295",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f5396a3707a9233a",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc16e93-bb60-49f4-fc22-c2b7263996a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.36569641 0.27310934 0.16738898 0.17222566 0.30155125]\n"
          ]
        }
      ],
      "source": [
        "##GRADED CELL\n",
        "\n",
        "scores_linear_training = None\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "scores_linear_training = clf.predict(X) #predict\n",
        "###END SOLUTION\n",
        "print(scores_linear_training[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c94467d",
      "metadata": {
        "id": "9c94467d",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-af4f2b2d7775e2f7",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "To perform classification on the training set, apply a cutoff value of 0.4 such that any predicted output greater than this threshold is classified as \"1\" (positive class), and otherwise as \"0\" (negative class). Then, manually compute the accuracy, sensitivity, and specificity using the confusion matrix components without relying on built-in functions. Finally, analyze and discuss the modelâ€™s performance based on these metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "67c7b0d9",
      "metadata": {
        "id": "67c7b0d9"
      },
      "outputs": [],
      "source": [
        "cutoff = 0.4 #cutoff value\n",
        "predicted_linear_training = (scores_linear_training >= cutoff) #take the scores, and apply the logical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5c6240d9",
      "metadata": {
        "id": "5c6240d9",
        "outputId": "b39ba4a8-4ece-44b2-e75a-c7b447c824f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "predicted_linear_training[:9] #here are some of the classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "11244724",
      "metadata": {
        "id": "11244724"
      },
      "outputs": [],
      "source": [
        "def metrics(cm): #this function returns relevant statistics\n",
        "    total = cm[0][0] + cm[1][1] +  cm[0][1] +  cm[1][0]\n",
        "    correct = cm[0][0] + cm[1][1]\n",
        "    accuracy = correct/total\n",
        "    specificity = cm[0][0] / (cm[0][0] + cm[0][1])\n",
        "    sensitivity = cm[1][1] / (cm[1][0] + cm[1][1])\n",
        "    return total, correct,accuracy,specificity,sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "eef8a1f7-7656-41d7-bff9-877d418c5e79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eef8a1f7-7656-41d7-bff9-877d418c5e79",
        "outputId": "dbcd6c54-7e06-4d35-d4cb-82b82c059665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "y_true = df_train.Target.astype(int).values          # ensure integer\n",
        "y_pred = predicted_linear_training.astype(int)       # convert boolean to integer\n",
        "print(y_true)\n",
        "print(y_pred)\n",
        "cm = confusion_matrix(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "4f07a780",
      "metadata": {
        "id": "4f07a780"
      },
      "outputs": [],
      "source": [
        "total_train, correct_train,accuracy_train,specificity_train,sensitivity_train \\\n",
        "= metrics(confusion_matrix(y_true, y_pred)) #get all the metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "faa02740",
      "metadata": {
        "id": "faa02740",
        "outputId": "3da4996f-55c4-4bb9-f9f6-ef810cd1afd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.795 \n",
            "Sensitivity: 0.464 \n",
            "Specificity: 0.903\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", round(accuracy_train,3), \"\\nSensitivity:\", round(sensitivity_train,3),\\\n",
        "      \"\\nSpecificity:\", round(specificity_train,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf8492d",
      "metadata": {
        "id": "bbf8492d"
      },
      "source": [
        "Observation:-\n",
        "- Accuracy is 79.6%, which is better than the 75% accuracy we can obtain if we say \"0\" to all.\n",
        "- Sensitivity is 47.9%, which is better than the 24% sensitivity we can obtain if we say \"1\" to all.\n",
        "- Both metrics improve the greedy method we applied."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1692f12e",
      "metadata": {
        "id": "1692f12e",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-1a678ba05ef88b42",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Q4.3: Apply the same on training set but decrease the cutoff down to 0.2. Inspect the metrics we looked before, and compare the results with the cutoff 0.4. Interpret the results.\n",
        "\n",
        "Use the `metrics()` defined above. The Accuracy, Sensitivity, Specificity are computed storing in `_,_,accuracy_train_alt,specificity_train_alt,sensitivity_train_alt`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b5ba4e46",
      "metadata": {
        "id": "b5ba4e46",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-28340616e4081928",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "###GRADED CELL\n",
        "_, _,accuracy_train_alt,specificity_train_alt,sensitivity_train_alt= None, None, None, None, None\n",
        "cutoff_altenative = 0.2 #cutoff value\n",
        "predicted_linear_training_alternative = (scores_linear_training >= cutoff_altenative)\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "_, _,accuracy_train_alt,specificity_train_alt,sensitivity_train_alt \\\n",
        "= metrics(confusion_matrix(y_true, predicted_linear_training_alternative.astype(int))) #get all the metrics\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ba4360b5",
      "metadata": {
        "id": "ba4360b5",
        "outputId": "1c6767b5-7e42-4188-d960-f26602fce136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.616 \n",
            "Sensitivity: 0.885 \n",
            "Specificity: 0.528\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", round(accuracy_train_alt,3), \"\\nSensitivity:\", round(sensitivity_train_alt,3),\\\n",
        "      \"\\nSpecificity:\", round(specificity_train_alt,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4250d60f",
      "metadata": {
        "id": "4250d60f"
      },
      "source": [
        "Observation:-\n",
        "- We have much better sensitivity at a cost of worse specificity. In return, overall accuracy gets worse."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9f47dc",
      "metadata": {
        "id": "2d9f47dc"
      },
      "source": [
        "Applying the linear model to the test set with a cutoff value of 0.4, the accuracy, sensitivity, and specificity are computed based on the resulting classifications using the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "3791ad1f",
      "metadata": {
        "id": "3791ad1f"
      },
      "outputs": [],
      "source": [
        "X_test = df_test[numericals] #extract predictors\n",
        "y_test = df_test.Target #same for test target\n",
        "cutoff_test = 0.4\n",
        "scores_linear_test = clf.predict(X_test)\n",
        "predicted_linear_test = (scores_linear_test >= cutoff_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "656e0200",
      "metadata": {
        "id": "656e0200"
      },
      "outputs": [],
      "source": [
        "_, _,accuracy_test,specificity_test,sensitivity_test \\\n",
        "= metrics(confusion_matrix(y_true, y_pred)) #get all the metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "859b225a",
      "metadata": {
        "id": "859b225a",
        "outputId": "cbbff9ad-164a-4a6c-8e6f-e43bff7db777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.795 \n",
            "Sensitivity: 0.464 \n",
            "Specificity: 0.903\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy:\", round(accuracy_test,3), \"\\nSensitivity:\", round(sensitivity_test,3),\\\n",
        "      \"\\nSpecificity:\", round(specificity_test,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc5a526",
      "metadata": {
        "id": "0cc5a526"
      },
      "source": [
        "In the previous question we tuned the cutoff value on the training set. This initialy makes sense, because we cannot tune on the test-set, which will be indirectly training on the test set. However, we also discussed in the validation-set approach that it is not a good practice to *compare* models on the training set, because of a natural bias in this procedure. Hence, it is a better approach to tune a value on a validation set. For this purpose, apply the following steps:\n",
        "\n",
        "- Split the training set as 80% (training) - 20% (validation) sets. You can take the first 80% and last 20% and no need to randomize the selection.\n",
        "- Train a linear model on the training set obtained in the previous approach. Training one model is enough.\n",
        "- Compare cutoff values between 0.2 - 0.8 with 0.05 increments. Pick the best model by looking at the validation set, where the \"best\" model has an accuracy over 76% and has the highest sensitivity still.\n",
        "- Test the validated cutoff on the test set and return the metrics.\n",
        "- [Extra / optional] Instead of the hold-out validation that you just applied, try 5-fold cross validation in the original training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "da684322",
      "metadata": {
        "id": "da684322",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Step 1 -- split\n",
        "training_nr = round(len(X)*0.8)\n",
        "train_80 = X[:training_nr]\n",
        "y_train_80 = df_train[:training_nr].Target #training target\n",
        "validate_20 = X[training_nr:]\n",
        "y_validate_20 = df_train[training_nr:].Target #training target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "011fa616",
      "metadata": {
        "id": "011fa616"
      },
      "outputs": [],
      "source": [
        "# Step 2 -- train\n",
        "clf = LinearRegression().fit(train_80, y_train_80) #time to fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8bf02b12",
      "metadata": {
        "id": "8bf02b12"
      },
      "outputs": [],
      "source": [
        "# Step 3 -- try cutoffs\n",
        "scores_linear_validation = clf.predict(validate_20) #predict\n",
        "cutoffs = np.arange(0.2,0.85, 0.05)\n",
        "max_cutoff = 0\n",
        "max_sensitivity = 0\n",
        "max_accuracy = 0  # Initialize max_accuracy\n",
        "for cutoff in cutoffs:\n",
        "    predicted_linear_validated = pd.Series(scores_linear_validation >= cutoff, index=validate_20.index)\n",
        "    # Convert y_validate_20 to integer and drop rows with NaN\n",
        "    y_validate_20_cleaned = y_validate_20.dropna().astype(int)\n",
        "    predicted_linear_validated_cleaned = predicted_linear_validated[y_validate_20_cleaned.index].astype(int) # Align predictions with cleaned target\n",
        "    _, _,accuracy_validate,specificity_validate, sensitivity_validate \\\n",
        "        = metrics(confusion_matrix(y_validate_20_cleaned, predicted_linear_validated_cleaned)) #get all the metrics\n",
        "    if accuracy_validate >= 0.76 and sensitivity_validate >= max_sensitivity:\n",
        "        max_cutoff = cutoff\n",
        "        max_sensitivity = sensitivity_validate\n",
        "        max_accuracy = accuracy_validate # Update max_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "585f5aa2",
      "metadata": {
        "id": "585f5aa2",
        "outputId": "06bc53f6-1bda-4bb4-b00f-89aff336418e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best cutoff value is 0.3 with a validation accuracy of 0.77 and a validation sensitivity of 0.722\n"
          ]
        }
      ],
      "source": [
        "print(\"The best cutoff value is\", max_cutoff, \"with a validation accuracy of\", round(max_accuracy,3), \\\n",
        "      \"and a validation sensitivity of\", round(max_sensitivity,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "fcb44d32",
      "metadata": {
        "id": "fcb44d32",
        "outputId": "62e401a5-52f3-451e-bc1b-5b05601605d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.745 \n",
            "Sensitivity: 0.689 \n",
            "Specificity: 0.763\n"
          ]
        }
      ],
      "source": [
        "# step 4 -- test this\n",
        "scores_validated_test = clf.predict(X_test)\n",
        "predicted_validated_test = (scores_validated_test >= max_cutoff)\n",
        "# Convert df_test.Target to integer and drop rows with NaN\n",
        "df_test_cleaned = df_test.dropna(subset=['Target']).copy()\n",
        "y_test_cleaned = df_test_cleaned.Target.astype(int).values\n",
        "predicted_validated_test_cleaned = predicted_validated_test[df_test_cleaned.index].astype(int) # Align predictions with cleaned target\n",
        "\n",
        "_, _,accuracy_test,specificity_test,sensitivity_test \\\n",
        "    = metrics(confusion_matrix(y_test_cleaned, predicted_validated_test_cleaned)) #get all the metrics\n",
        "print(\"Accuracy:\", round(accuracy_test,3), \"\\nSensitivity:\", round(sensitivity_test,3),\\\n",
        "      \"\\nSpecificity:\", round(specificity_test,3)) #we are done!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9da33b6d",
      "metadata": {
        "id": "9da33b6d"
      },
      "source": [
        "### Final notes\n",
        "Linear regression is not inherently suited for classification tasks, but it can perform reasonably well in some cases. Logistic regression, a related method, models a linear relationship like linear regression but applies a nonlinear transformation to produce outputs between 0 and 1. This allows straightforward classification by assigning instances with predicted values â‰¥ 0.5 to class \"1,\" with the threshold adjustable as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "5efb6968",
      "metadata": {
        "id": "5efb6968"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X, y.dropna().astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "8e4949d9",
      "metadata": {
        "id": "8e4949d9"
      },
      "outputs": [],
      "source": [
        "scores_linear_training = clf.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "006a7367",
      "metadata": {
        "id": "006a7367"
      },
      "outputs": [],
      "source": [
        "#Clean the target column and align with predictions\n",
        "y_true_cleaned = df_train.Target.dropna().astype(int)\n",
        "# Get the index of the cleaned target values\n",
        "cleaned_index = y_true_cleaned.index\n",
        "# Select the predicted values corresponding to the cleaned target values using their positional index\n",
        "y_pred_aligned = scores_linear_training[df_train.Target.dropna().index.map(df_train.Target.index.get_loc).values]\n",
        "\n",
        "total_train, correct_train,accuracy_train,specificity_train,sensitivity_train \\\n",
        "= metrics(confusion_matrix(y_true_cleaned, y_pred_aligned))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb7d172-7330-4d6e-9c15-a175d75977b3",
      "metadata": {
        "id": "8cb7d172-7330-4d6e-9c15-a175d75977b3"
      },
      "source": [
        "#### Applying Logistic Regression model to the test set\n",
        "\n",
        "Now we will apply the trained Logistic Regression model to the test set and evaluate its performance using accuracy, sensitivity, and specificity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "bb6b86ee-0bf5-486d-966f-3e48e8b55433",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb6b86ee-0bf5-486d-966f-3e48e8b55433",
        "outputId": "2700b96c-2c40-4bea-84a0-30bb1eaa6197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Metrics on Test Set:\n",
            "Accuracy: 0.813\n",
            "Sensitivity: 0.387\n",
            "Specificity: 0.945\n"
          ]
        }
      ],
      "source": [
        "X_test_cleaned = X_test.dropna() # Drop rows with NaN in test predictors for consistency\n",
        "# Align the test target with the cleaned test predictors\n",
        "y_test_cleaned_aligned = df_test.loc[X_test_cleaned.index, 'Target'].dropna().astype(int)\n",
        "\n",
        "# Predict on the cleaned test data\n",
        "scores_logistic_test = clf.predict(X_test_cleaned)\n",
        "\n",
        "# Convert scores to a pandas Series with the same index as the cleaned predictors\n",
        "predicted_logistic_test_series = pd.Series(scores_logistic_test, index=X_test_cleaned.index)\n",
        "\n",
        "# Align the predicted values with the cleaned test target\n",
        "predicted_logistic_test_aligned = predicted_logistic_test_series.loc[y_test_cleaned_aligned.index]\n",
        "\n",
        "# Calculate metrics\n",
        "_, _, accuracy_logistic_test, specificity_logistic_test, sensitivity_logistic_test \\\n",
        "    = metrics(confusion_matrix(y_test_cleaned_aligned, predicted_logistic_test_aligned))\n",
        "\n",
        "print(\"Logistic Regression Metrics on Test Set:\")\n",
        "print(\"Accuracy:\", round(accuracy_logistic_test, 3))\n",
        "print(\"Sensitivity:\", round(sensitivity_logistic_test, 3))\n",
        "print(\"Specificity:\", round(specificity_logistic_test, 3))"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "collapsed_sections": [
        "9639540b",
        "7a066ee9",
        "2f534fd6",
        "9410daff",
        "588c3746",
        "9a48a450",
        "61367d5f",
        "22e18ccb",
        "0e29a2aa",
        "c0bb3c5a",
        "e0550f2a",
        "1d5dd1fd",
        "5b54db7c",
        "4fe26a6a",
        "dfe90132",
        "237e267f",
        "2072749d",
        "a3c8361e",
        "a02a1dac",
        "c9e60fbc",
        "56f8ec48",
        "9425aed5",
        "6adbc2d6",
        "c2bf9449",
        "cc096ae1",
        "76b23df8",
        "d2964a3d",
        "1fab9881",
        "c56bbdcc",
        "e48bcd3d",
        "b5d8ed38",
        "47ad2428",
        "d4676022",
        "9d93ccfd",
        "8f576364",
        "d0b18c3a",
        "302f07c3",
        "7b358bd4",
        "ba7483bd",
        "388e440f",
        "d8c629a2",
        "dbc5a5ed",
        "894f65c6",
        "ec37e32c",
        "54989749",
        "9632323d",
        "47d16395",
        "c76da1ec",
        "d6a4ec6d"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}